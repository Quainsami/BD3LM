CONFIG
├── mode
│   └── ppl_eval                                                                                                                                                                                                                                   
├── diffusion
│   └── absorbing_state                                                                                                                                                                                                                            
├── seed
│   └── 1                                                                                                                                                                                                                                          
├── block_size
│   └── 4                                                                                                                                                                                                                                          
├── loader
│   └── global_batch_size: 512                                                                                                                                                                                                                     
│       eval_global_batch_size: 512                                                                                                                                                                                                                
│       batch_size: 512                                                                                                                                                                                                                            
│       eval_batch_size: 16                                                                                                                                                                                                                        
│       num_workers: 128                                                                                                                                                                                                                           
│       pin_memory: true                                                                                                                                                                                                                           
│                                                                                                                                                                                                                                                  
├── sampling
│   └── noise_removal: false                                                                                                                                                                                                                       
│       num_sample_batches: 1                                                                                                                                                                                                                      
│       var_length: false                                                                                                                                                                                                                          
│       logdir: ./samples_bd3lm_len1024_blocksize4                                                                                                                                                                                                 
│       nucleus_p: 1.0                                                                                                                                                                                                                             
│       first_hitting: true                                                                                                                                                                                                                        
│       kv_cache: false                                                                                                                                                                                                                            
│                                                                                                                                                                                                                                                  
├── training
│   └── ema: 0.9999                                                                                                                                                                                                                                
│       antithetic_sampling: true                                                                                                                                                                                                                  
│       sampling_eps: 0.001                                                                                                                                                                                                                        
│       coeff_clip: -1.0                                                                                                                                                                                                                           
│       resample: false                                                                                                                                                                                                                            
│       sampling_eps_min: 0.001                                                                                                                                                                                                                    
│       sampling_eps_max: 1.0                                                                                                                                                                                                                      
│       from_pretrained: null                                                                                                                                                                                                                      
│       eval_nll: true                                                                                                                                                                                                                             
│                                                                                                                                                                                                                                                  
├── eval
│   └── checkpoint_path: kuleshov-group/bd3lm-owt-block_size4                                                                                                                                                                                      
│       disable_ema: false                                                                                                                                                                                                                         
│       perplexity_batch_size: 8                                                                                                                                                                                                                   
│       compute_perplexity_on_sanity: false                                                                                                                                                                                                        
│       gen_ppl_eval_model_name_or_path: gpt2-large                                                                                                                                                                                                
│       generate_samples: false                                                                                                                                                                                                                    
│                                                                                                                                                                                                                                                  
├── optim
│   └── weight_decay: 0                                                                                                                                                                                                                            
│       lr: 0.0003                                                                                                                                                                                                                                 
│       beta1: 0.9                                                                                                                                                                                                                                 
│       beta2: 0.999                                                                                                                                                                                                                               
│       eps: 1.0e-08                                                                                                                                                                                                                               
│                                                                                                                                                                                                                                                  
├── trainer
│   └── _target_: lightning.Trainer                                                                                                                                                                                                                
│       accelerator: cuda                                                                                                                                                                                                                          
│       num_nodes: 1                                                                                                                                                                                                                               
│       devices: 1                                                                                                                                                                                                                                 
│       accumulate_grad_batches: 1                                                                                                                                                                                                                 
│       gradient_clip_val: 1.0                                                                                                                                                                                                                     
│       precision: bf16                                                                                                                                                                                                                            
│       num_sanity_val_steps: 2                                                                                                                                                                                                                    
│       max_steps: 1000000                                                                                                                                                                                                                         
│       log_every_n_steps: 1000                                                                                                                                                                                                                    
│       limit_train_batches: 1.0                                                                                                                                                                                                                   
│       limit_val_batches: 1.0                                                                                                                                                                                                                     
│       val_check_interval: 10000                                                                                                                                                                                                                  
│                                                                                                                                                                                                                                                  
├── wandb
│   └── None                                                                                                                                                                                                                                       
├── checkpointing
│   └── save_dir: /workspace/bd3lms/outputs/openwebtext-train/2025.05.16/073608                                                                                                                                                                    
│       resume_from_ckpt: true                                                                                                                                                                                                                     
│       resume_ckpt_path: /workspace/bd3lms/outputs/openwebtext-train/2025.05.16/073608/checkpoints/last.ckpt                                                                                                                                      
│                                                                                                                                                                                                                                                  
├── callbacks
│   └── checkpoint_every_n_steps:                                                                                                                                                                                                                  
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                                                                                                                                                    
│         save_top_k: -1                                                                                                                                                                                                                           
│         save_last: true                                                                                                                                                                                                                          
│         dirpath: /workspace/bd3lms/outputs/openwebtext-train/2025.05.16/073608/checkpoints                                                                                                                                                       
│         verbose: true                                                                                                                                                                                                                            
│         auto_insert_metric_name: false                                                                                                                                                                                                           
│         every_n_train_steps: 500                                                                                                                                                                                                                 
│       checkpoint_monitor:                                                                                                                                                                                                                        
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                                                                                                                                                    
│         monitor: val/nll                                                                                                                                                                                                                         
│         mode: min                                                                                                                                                                                                                                
│         save_top_k: 1                                                                                                                                                                                                                            
│         save_last: false                                                                                                                                                                                                                         
│         dirpath: /workspace/bd3lms/outputs/openwebtext-train/2025.05.16/073608/checkpoints                                                                                                                                                       
│         filename: best                                                                                                                                                                                                                           
│         auto_insert_metric_name: false                                                                                                                                                                                                           
│         verbose: true                                                                                                                                                                                                                            
│       learning_rate_monitor:                                                                                                                                                                                                                     
│         _target_: lightning.pytorch.callbacks.LearningRateMonitor                                                                                                                                                                                
│         logging_interval: step                                                                                                                                                                                                                   
│                                                                                                                                                                                                                                                  
├── data
│   └── train: openwebtext-train                                                                                                                                                                                                                   
│       valid: openwebtext-valid                                                                                                                                                                                                                   
│       tokenizer_name_or_path: gpt2                                                                                                                                                                                                               
│       cache_dir: /share/kuleshov/ssahoo/textdiffusion/data                                                                                                                                                                                       
│       wrap: true                                                                                                                                                                                                                                 
│       streaming: false                                                                                                                                                                                                                           
│       insert_train_eos: true                                                                                                                                                                                                                     
│       insert_valid_eos: true                                                                                                                                                                                                                     
│       insert_train_special: true                                                                                                                                                                                                                 
│       insert_valid_special: false                                                                                                                                                                                                                
│                                                                                                                                                                                                                                                  
├── model
│   └── name: small                                                                                                                                                                                                                                
│       type: ddit                                                                                                                                                                                                                                 
│       hidden_size: 768                                                                                                                                                                                                                           
│       cond_dim: 128                                                                                                                                                                                                                              
│       length: 1024                                                                                                                                                                                                                               
│       n_blocks: 12                                                                                                                                                                                                                               
│       n_heads: 12                                                                                                                                                                                                                                
│       scale_by_sigma: true                                                                                                                                                                                                                       
│       dropout: 0.1                                                                                                                                                                                                                               
│       tie_word_embeddings: true                                                                                                                                                                                                                  
│       adaln: false                                                                                                                                                                                                                               
│       attn_backend: flex                                                                                                                                                                                                                         
│                                                                                                                                                                                                                                                  
├── strategy
│   └── _target_: lightning.pytorch.strategies.DDPStrategy                                                                                                                                                                                         
│       find_unused_parameters: false                                                                                                                                                                                                              
│                                                                                                                                                                                                                                                  
├── noise
│   └── type: loglinear                                                                                                                                                                                                                            
│       sigma_min: 0.0001                                                                                                                                                                                                                          
│       sigma_max: 20                                                                                                                                                                                                                              
│                                                                                                                                                                                                                                                  
├── lr_scheduler
│   └── _target_: transformers.get_constant_schedule_with_warmup                                                                                                                                                                                   
│       num_warmup_steps: 2500                                                                                                                                                                                                                     
│                                                                                                                                                                                                                                                  
└── algo
    └── name: bd3lm                                                                                                                                                                                                                                
        backbone: hf_dit                                                                                                                                                                                                                           
        parameterization: subs                                                                                                                                                                                                                     
        time_conditioning: false                                                                                                                                                                                                                   
        T: 0                                                                                                                                                                                                                                       
        causal_attention: false                                                                                                                                                                                                                    
        dropout: 0.0                                                                                                                                                                                                                               
        ignore_bos: true                                                                                                                                                                                                                           
        cross_attn: true                                                                                                                                                                                                                           
        var_min: true                                                                                                                                                                                                                              
        clip_search_delta: 0.05                                                                                                                                                                                                                    
        clip_search_widths: []                                                                                                                                                                                                                     
        fix_clipping: false                                                                                                                                                                                                                        
        sampler: semi_ar                                                                                                                                                                                                                           
        mdlm_loss_scale: false                                                                                                                                                                                                                     
                                                                                                                                                                                                                                                   
